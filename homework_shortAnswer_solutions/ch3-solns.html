<html>
  <head>
    <title>Homework Solutions for Operating Systems</title>
    <!-- The following is std, but needs access to cs.nyu.edu -->
    <link rel="stylesheet" type="text/css"
	  href="http://cs.nyu.edu/~gottlieb/css/courses.css"/>
    <!-- Firefox treats the next as relative; I use it when off the net -->
    <link rel="stylesheet" type="text/css"
	  href="http:/~gottlieb/css/courses.css"/>
    <link rel="shortcut icon" href="//cs.nyu.edu/~gottlieb/favicon.ico"/>
  </head>

<body>

<h1>Chapter 3: Memory Management</h1>

<p><strong>Problem:</strong> What is the difference between a physical
  address and a virtual address?</p>
<p><strong>Solution:</strong>
  Real memory uses physical addresses. These are the numbers that
  the memory chips react to on the bus. Virtual addresses are the logical
  addresses that refer to a process' address space. Thus a machine with a
  16-bit word can generate virtual addresses up to 64K, regardless of
  whether the machine has more or less memory than 64K.</p>

<h2>3.2: A Memory Abstraction: Address Spaces</h2>

<p><strong>Problem:</strong> 3. A swapping system eliminates holes by
  compaction.
  Assume a random distribution of holes and data segments, assume the
  data segments are much bigger than the holes, and assume a time to
  read or write a 32-bit memory word of 4ns.
  About how long does it
  take to compact 4 GB?
  For simplicity, assume that word 0 is part of a hole and the highest
  word in memory conatains valid data.</p>
<p><strong>Solution:</strong> Almost the entire memory has to be
  copied, which requires each word to be read and then rewritten to a
  different location.
  Reading 4 bytes takes 4ns so reading 1 byte takes 1ns and we
  assume writing also takes 1ns for a total of 2ns per byte
  compacted.
  So to copy 4GB, takes about 8 billion ns or 8 seconds.</p><hr/>

<p><strong>Problem:</strong> 4.  Consider a swapping system in which
  memory consists of the following hole sizes in memory order: 10MB,
  4MB, 20MB, 18MB 7MB, 9MB, 12MB, and 15MB.
  Which hole is taken for successive segment requests of</p>
  <ol type="a">
    <li>12MB</li>
    <li>10MB</li>
    <li>9MB</li>
  </ol>
<p>for first fit?<br/>
  Now repeat the question for best fit, worst fit, and next fit.</p>
<p><strong>Solution:</strong> First fit takes 20k, 10k, 18k.<br/>
  Best fit takes 12MB, 10MB, 9MB.<br/>
  Worst fit takes 20k, 18MB, 15MB.<br />
  Next fit takes 20MB, 18MB, 9MB.</p><hr/>

<!-- 2ed problem omitted for 3ed.  Should I put it back?
     would need to copy the problem statement into class-notes.html.

<p><strong>Problem:</strong> 4-16.
Below is the execution trace of a program fragment for a computer with
512-byte pages.  The program is loacated at address 1020, and its
stack pointer is a at 8192 (the stack grows toward 0).  Give the page
reference string generated by this program.  Each instruction occupies
4 bytes (1 word) including immediate constants.  Both instructions and
data references count in the reference string.
<ol>
<li>Load word 6144 into register 0.
<li>Push register 0 onto the stack
<li>Call a procedure at 5120, stacking the return address
<li>Subtract the immediate constant 16 from the stack pointer
<li>Compare the actual parameter to the immediate constant 4
<li>Jump if equal to 5152
</ol>

<p><strong>Solution:</strong>
The reference string is 1(I), 12(D); 2(I), 15(D); 2(I), 15(D); 10(I);
10(I), 15(D); 10(I). The code (I) indicates an instruction reference,
whereas (D) indicates a data reference. Semicoloins give the
instruction boundaries.

<p>Here is an explanation of the first few references.

<p>The program is loaded at addr 1020 so we start with an instruction
reference to location 1020.  Since the page size is 512 the page
referenced is 1020 div 512 (i.e. &lfloor;1020/512&rfloor;), which is 1.  This
is an instruction fetch and explains the initial 1(I) in the answer.
Now that we have fetched the instruction, we must execute it.  Loading
the word at 6144 requires a data reference to location 6144, which is
page 12, explaining the 12(D).

<p>Now we fetch the next instruction which is at 1024, i.e. page 2 and
explains the 2(I).  Now we execute the instruction.  The stack pointer
is given as 8192.  When you push onto a stack you either pre or post
decrement the stack pointer (since the stack grows toward 0).  In C or java
you are referencing either stack[--ptr] or stack[ptr--].  It is
explained elsewhere in the text that tanenbaum uses the convention
--ptr, i.e. pre-decrementing.  So the stack is referenced at location
8192-4 or 8188, which is page 15 and explains the 15(D).

<p>Now we fetch an instruction at 1028, i.e., page 2.
Stacking the return address references 8188-4=8184 (page 15) and sets
the stack pointer to 8184.

<p>Because of the procedure call the next I fetch is at 5120, which is
page 10.
Changing the stack pointer does not reference memory so there is no D
reference, but the pointer is reduced from 8184 to 8168.
 -->

<p><strong>Problem:</strong>
  7.  Using the page table of Fig. 3.9, give the physical address
  corresponding to each of the following virtual addresses.
  <ol style="a">
    <li>20
    <li>4100
    <li>8300
  </ol>
<p><strong>Solution:</strong>
<p>(a) 8212 (b) 4100 (c) 24684

<h2>3.3: Virtual Memory (meaning fetch on demand)</h2>

<p><strong>Problem:</strong> 3-14.
<p>A machine has a 32-bit address space and an 8-KB page.
  The page table is entirely in hardware, with one 32-bit word per
  entry.
  When a process starts, the page table is copied to the hardware from
  memory, at one word every 100 nsec.
  If each process runs for 100 msec (including the time to load the page
  table), what fraction of the CPU time is devoted to loading the page
  tables?</p>
<p><strong>Solution:</strong>
  The page table contains (2^32)/(2^13) entries, which is
  524,288. Loading the page table takes 52 msec. If a process gets 100
  msec, this consists of 52 msec for loading the page table and 48 msec
  for running. Thus 52 percent of the time is spent loading page table
<p>In response to a query from a student I gave the following more
  detailed answer.
  <ol>
    <li>32-bit address space means 2^32 bytes.
    <li>An 8KB page has 8*1024 = 2^3 * 2^10 = 2^13 bytes.
    <li>The number of pages is (num of bytes) / (num bytes per page) =
      2^32 / 2^13 = 2^19 = 524,288.
    <li>The page table has one entry PTE per page or 524,288 entries.
    <li>Each PTE is a word, which takes 100ns to load.
    <li>Loading all 524,288 entries takes 52,428,800nsc = 52.4288msec,
      which I approximated as 52msec.
    <li>Since the program runs for 100ms (including loading the table),
      the table load is 52msec/100ms = 52/100 = 52% of the time.
  </ol><hr/>

<p><strong>Problem:</strong> 22.
<p>A computer whose processes have 1024 pages in their address spaces
  keeps its page tables in memory.
  The overhead required for reading a word from the page table is 5
  nsec.
  To reduce this overhead, the computer has a TLB, which holds 32
  (virtual page, physical page frame) pairs, and can do a look up in 1
  nsec.
  What hit rate is needed to reduce the mean overhead to 2 nsec?
<p><strong>Solution:</strong>
  The effective instruction time is
  1h+5(1-h), where h is the hit rate. If we equate this formula with
  2 and solve for h we find that h must be at least
  0.75.
<p>In response to a query from a student I gave the following more
  detailed answer.</p>
<ol>
  <li>For a TLB hit, the overhead is 1ns.</li>
  <li>For a TLB miss, the overhead is 5ns.</li>
  <li>The (TLB) hit rate h is the fraction of requests that are
    satisfied by the TLB (and hence take 1ns).</li>
  <li>(1-h) is the fraction of requests that are not satisfied by the
    TLB (and hence take 5ns).</li>
  <li>The average overhead is thus h*1ns + (1-h)*5ns = (5-4h)ns.</li>
  <li>To have (5-4h)ns &lt;= 2ns requires 5-4h &lt;= 2 or h &gt;= 3/4.</li>
</ol>

<h2>3.4: Page Replacement Algorithms</h2>

<p><strong>Problem:</strong> 28.
  If FIFO page replacement is used with four page frames and eight pages,
  how many page faults will occur with the reference string 0172327103 if
  the four frames are initially empty? Now repeat this problem for LRU.
<p><strong>Solution:</strong>
<p>FIFO:
  <pre>
     0172327103
    x0172333300
    xx017222233
    xxx01777722
    xxxx0111177
  </pre>
  6 page faults
<p>LRU:
  <pre>
     0172327103
    x0172327103
    xx017232710
    xxx01773271
    xxxx0111327
  </pre>
  7 page faults.
<hr/>

<strong>Problem:</strong> 36.
<p>A computer has four page frames. The time of loading, time of last access,
  and the R and M bits for each page are shown below (the times in clock
  ticks).</p>
<table border="1">
  <tr><th>Page<th>Loaded<th>Last ref.<th>R<th>M</tr>
    <tr><td>0<td>126<td>280<td>1<td>0</tr>
    <tr><td>1<td>230<td>265<td>0<td>1</tr>
    <tr><td>2<td>140<td>270<td>0<td>0</tr>
    <tr><td>3<td>110<td>285<td>1<td>1</tr>
  </table>
  <ol type=a>
    <li>Which page will NRU replace?</li>
    <li>Which page will FIFO replace?</li>
    <li>Which page will LRU replace?</li>
    <li>Which page will second chance replace?</li>
  </ol>
    
<p><strong>Solution:</strong>
  <ol type=a>
    <li>2
    <li>3
    <li>1
    <li>2
  </ol>
<hr/>

<p><strong>Problem:</strong> 30.
<p>A small computer on a smart card has four page frames.
  At the first clock tick, the R bits
  are 0111 (page 0 is 0, the rest are 1). At subsequent clock ticks, the
  values are 1011, 1010, 1101, 0010, 1010, 1100 and 0001. If the aging algorithm
  is used with an 8-bit counter, give the values of the four counters after
  the last tick.</p>
<p><strong>Solution:</strong></p>
<pre>
  Page0: 01101110
  Page1: 01001001
  Page2: 00110111
  Page3: 10001011
</pre>
<hr/>

<p><strong>Problem:</strong> 42.
<p>It has been observed that the number of instructions executed between page
  faults is directly proportional to the number of page frames allocated to
  a program. If the available memory is doubled, the mean interval between
  page faults is also doubled. Suppose that a normal instruction takes 1 us,
  but if a page fault occurs, it takes 2001 us. If a program takes 60 sec to
  run, during which time it gets 15,000 page faults, how long would it take
  to run if twice as much memory were available?
<p><strong>Solution:</strong>
  The program is getting 15,000 page faults, each of which 2 ms of extra
  processing time (remember, 2001 us = 2000 us (page fault) + 1 us
  (instruction execution)). Together, the page fault overhead is 30 seconds.
  This means that of the 60 sec used, half was spent on page fault overhead,
  and half on running the program. If we run the program with twice as much
  memory, given the same number of instructions to execute, we get half as
  many page faults (15 sec). So overall execution time is 45 seconds.
  (30 sec of instruction execution + 15 sec of page fault overhead)<hr/>

<p><strong>Problem:</strong> Describe a process (i.e., a program)
  that runs for a long time (say hours) and always has a working set
  size less than 10.
  Assume k=100,000, the page size is 4KB.
  The program need not be practical or useful.</p>
<p><strong>Solution</strong>
  A tight loop referencing very little data.  A trivial example is</p>
<pre>
  x &larr;  0
    For i from 1 to 100000000
      For j from 1 to 100000000
        x &larr;  x + i - j
</pre><hr/>

<p><strong>Problem:</strong> Describe a process that runs for a
  long time and (except for the very beginning of execution) always
  has working set size greater than 1000.
  Assume k=100,000 and the page size is 4KB.
  The program need not be practical or useful.</p>
<p><strong>Solution</strong>
  Reference a new page every iteration.</p>
<pre>
  for j from 1 to 1000000000
    for i from 1 to 1001
      X[i*4096] = j
</pre>

<h2>3.5 Design issues for (demand) Paging Systems</h2>

<p><strong>Problem:</strong> Consider a 32-bit address machine using
  paging with 8KB pages and 4 byte PTEs.
  How many bits are used for the offset and what is the size of the
  largest page table?
  Repeat the question for 128KB pages.</p>
<p><strong>Solution</strong> Each page is 8KB, which needs 13 bits to
  express.
  This is the size of the offset.
  There are 19-bits for the page number so 2^19 pages are possible.
  Hence the largest possible page table has 2^19 PTEs or 2^21 bytes.
<p>Each page is 128KB, which needs 17 bits to express.
  There are 15 bits for the page number so the largest page table has
  2^15 PTEs or 2^17 bytes.</p><hr/>

<p><strong>Problem:</strong>
  Can a page shared between two processes be read-only for one process
  and read-write for the other?
<p><strong>Solution:</strong> Yes.
  Assuming that segmentation is not present, the protection
  information must be in the page table.
  Since each process has its own page table, each one also has its own
  protection bits.
  The the protection bits could be different for the two processes.

<h2>3.6 Implementation Issues</h2>

<p><strong>Problem:</strong> Assume every memory reference takes 0.1
  microseconds to execute providing the reference page is memory
  resident.
  Assume a page fault takes 10 milliseconds to service providing the
  necessary disk block is actually on the disk.
  Assume a disk block fault takes 10 seconds service.
  So the worst case time for a memory reference is 10.0100001 seconds.
  Finally assume the program requires that a billion memory references
  be executed.
  <ol>
    <li>If the program is always completely resident, how long does it
      take to execute?
    <li>If 0.1% of the memory references cause a page fault, but all the disk
      blocks are on the disk, how long does the program take to execute
      and what percentage of the time is the program waiting for a page
      fault to complete?
    <li>If 0.1% of the memory references cause a page fault and 0.1% of the
      page faults cause a disk block fault, how long does the program
      take to execute and what percentage of the time is the program
      waiting for a disk block fault to complete?
  </ol>
<p><strong>Solution:</strong>
  <ol>
    <li>In this case the answer is <tt>#refs * time/ref = <br>
      10<sup>9</sup>*10<sup>-7</sup>sec = 100</tt> seconds
    <li>Now the answer is
      <tt>
        #refs * time/ref   +   #faults * "penalty for fault" = <br>
        #refs * time/ref +
        (#refs * fraction of refs that fault) * "penalty for fault" =<br>
        100sec + 10<sup>9</sup>*.001*10ms =
        (100 + 10000)sec = 10100
      </tt> seconds<br>
      <tt>10000/10100 = 100/101</tt> or approximately <tt>99%</tt>
    <li>In this last case the answer is<br>
      <tt>
        #refs * time/ref + <br>
        (#refs * fraction of refs that fault) * "penalty for fault" +<br>
        (#refs * fraction of refs that fault *
        fraction of faults that disk fault) * "penalty for disk fault"
      </tt>
      This is
      <tt>10100sec + 10<sup>9</sup>*.001*.001*10sec =
        (10100 + 10000)sec = 20100</tt> seconds<br>
      <tt>10000/20100 = 200/201</tt> or approximately <tt>49.75%</tt>
  </ol>
</p>

<h2>3.7: Segmentation</h2>

<p><strong>Problem:</strong>
  Explain the difference between internal fragmentation and external
  fragmentation.
  Which on occurs in paging systems?
  Which one occurs in systems using pure segmentation?
<p><strong>Solution:</strong> Internal fragmentation occurs when the
  last allocation unit is not full.
  External fragmentation occurs when space is wasted between two
  allocation units.
  In a paging system, the wasted space in the last page is lost to
  internal fragmentation.
  In a pure segmentation system, some space is invariably lost between
  the segments.
  This is due to external fragmentation.<hr/>

<p><strong>Problem:</strong> 46</p>
<p><strong>Solution:</strong> No.
  The search key uses both the segment number and the virtual page
  number, so the exact page can be found in a single match.</p>
<hr/>

<p><strong>Problem:</strong> Consider a 32-bit address machine using
  paging with 8KB pages and 4 byte PTEs.
  How many bits are used for the offset and what is the size of the
  largest page table?
  Repeat the question for 128KB pages.
  So far this question has been asked before.
  Repeat both parts if the system also has segmentation with at most
  128 segments.</p>
<p><strong>Solution</strong>
  Each page is 8KB, which needs 13 bits to express.  This is the size of
  the offset.
  There are 19-bits for the page number so 2^19 pages are possible.
  Hence the largest possible page table has 2^19 PTEs or 2^21 bytes.</p>
<p>Each page is 128KB, which needs 17 bits to express.
  There are 15 bits for the page number so the largest page table has
  2^15 PTEs or 2^17 bytes.</p>
<p>128 segments means that the segment number takes 7 bits.  Since the
  offset still requires 13 bits for 8K pages, we have 32-(7+13)=12
  bits for the page number.
  Hence there are at most 2^12 pages per segment and the size of the
  largest page table is 2^14.
  (Remember that with segmentation and paging there is a page table
  for each segment.
  This page table contains a PTE for each page in the segment.)</p>
<p>The Segment number still requires 7 bits.
  The offset is now 17 bits, which leaves 32-(17+7)=8 bits for the
  page number.
  Hence 2^8 pages in a segment and 2^10 is the largest page table
  size.</p>
<hr/>

<p><strong>Problem:</strong>
  Consider a system with 36-bit addresses that employs both
  segmentation and paging.
  Assume each PTE and STE is 4-bytes in size</p>
<ol class="compact">
  <li>Assume the system has a page size of 8K and each process can
    have up to 256 segments.
    How large in bytes is the largest possible page table?
    How large in pages is the largest possible segment?</li>
  <li>Assume the system has a page size of 4K and each segment can
    have up to 1024 pages.
    What is the maximum number of segments a process can have?
    How large in bytes is the largest possible segment table?
    How large in bytes is the largest possible process.</li>
  <li>Assume the largest possible segment table is 2<sup>13</sup>
    bytes and the largest possible page table is 2<sup>16</sup>
    bytes.
    How large is a page?
    How large in bytes is the largest possible segment?</li>
</ol>
<p><strong>Solution:</strong></p>
<ol>
  <li>Page size 8K implies 13-bit offsets.
    Max of 256 segments implies 8-bit segment numbers.
    Hence 36-13-8 or 15-bit page numbers.
    The largest possible page table has 2<sup>15</sup> PTEs, which
    requires 2<sup>17</sup> bytes.
    The largest possible segment has 2<sup>15</sup> pages.</li>
  <li>Page size 4K implies 12-bit offsets.</li>
  <li>Each segment can have up to 1024=2<sup>10</sup> pages implies
    10-bit page numbers.
    Hence 36-12-10=14-bit segment numbers.
    Hence a process can have up to 2<sup>14</sup> segments.
    The largest possible segment table has 2<sup>14</sup> STEs,
    which requires 2<sup>16</sup> bytes.
    The largest possible process has 2<sup>14</sup> segments each
    with 2<sup>10</sup> pages (10-bit page number) each of size 4K.
    Thus the size is 2<sup>14</sup>2<sup>10</sup>4K=2<sup>36</sup>.
    (You could also get 2<sup>36</sup> directly by noting that there
    are 36-bits of address, each can be 0 or 1.)</li>
  <li>Largest possible segment table is 2<sup>13</sup> bytes means a
    segment table can have up to 2<sup>11</sup> STEs so a process
    can have up to 2<sup>11</sup> segments and the segment number
    requires 11 bits.
    Similarly, a segment can have up to 2<sup>14</sup> pages and the
    page number requires 14 bits.
    Hence the offset requires 36-11-14=11 bits and the page size is
    2<sup>11</sup> bytes.
    The largest segment has 2<sup>14</sup> pages each 2<sup>11</sup>
    bytes so the largest segment has 2<sup>25</sup> bytes.</li>
</ol>
</body>
</html>
