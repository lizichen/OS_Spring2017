<html>
  <head>
    <title>Homework Solutions for Operating Systems</title>
    <!-- The following is std, but needs access to cs.nyu.edu -->
    <link rel="stylesheet" type="text/css"
	  href="http://cs.nyu.edu/~gottlieb/css/courses.css"/>
    <!-- Firefox treats the next as relative; I use it when off the net -->
    <link rel="stylesheet" type="text/css"
	  href="http:/~gottlieb/css/courses.css"/>
    <link rel="shortcut icon" href="//cs.nyu.edu/~gottlieb/favicon.ico"/>
  </head>

<body>


<h1>Chapter 4: File Systems</h1>

<h2>4.1: Files</h2>

<p><strong>Problem:</strong> 4.4.
  Is the open system call in UNIX absolutely essential?
  What would be the consequences of not having it?</p>
<p><strong>Solution:</strong> It is not essential.
  Were it not present the system would have to open the file as part
  of the first read or write.
  This would require a version of read/write giving the file name.
  Alternatively, read/write could always accept the file name and not
  the file descriptor, but that would be very inefficient since the
  action of open would be repeated on every access.</p>
<hr />

<p><strong>Problem:</strong> 4.5.
  Systems that support sequential files always have an operation to
  rewind files.
  Do systems that support random-access files need this, too?</p>
<p><strong>Solution:</strong>
  No.
  If you want to read the file again, just seek to byte 0.<hr/>

<p><strong>Problem:</strong> 4.6.
  Some operating systems provide a system call RENAME to give a file a
  new name.
  Is there any difference at all between using the call to rename a
  file and just copying the file to a new file wit the new name,
  followed by deleting the old one?</p>
<p><strong>Solution:</strong> Yes.
  The RENAME call does not change the creation time or the time of
  last modification, but creating a new file causes it to get the
  current time as both the creation time and the time of last
  modification.
  Also if the disk is full the copy might fail.
  In addition RENAME would be atomic with respect to other system
  calls so you would not have a (short) time in which there are
  actually two copies of the file.</p>
<hr />

<h2>4.2: Directories</h2>

<p><strong>Problem:</strong>
  Give 8 different path names for the file /etc/passwd.</p>
<p><strong>Solution:</strong>
  You can go up and down the tree as often as you want
  using <q>..</q>.
  You can also stand still with <q>.</q>.
  Some of the many paths are:</p>
<pre>
  /etc/passwd/
  /./etc/passwd
  /././etc/passwd
  /./././etc/passwd
  /etc/../etc/passwd
  /etc/../etc/../etc/passwd
  /etc/././../etc/passwd
  /etc/./../etc/./../etc/passwd
</pre><hr/>

<p><strong>Problem:</strong> 4.8.
  A simple operating system supports on ly a single directory but
  allows it to have arbitrarily many files with arbitrarily long file
  names.
  Can something approximating a hierarchical file system be simulated?
  How?</p>
<p><strong>Solution:</strong> Yes.
  Use file names such as /home/gottlieb/file.
  While it looks like a hierarchical path name, it is really just a
  single name containing embedded slashes.</p>

<h2>4.3: File System Implementation</h2>

<p><strong>Problem:</strong> 4.11 (corrected).
  Contiguous allocation of files leads to disk fragmentation.
  Is this internal fragmentation or external fragmentation?
  Make an analogy with something discussed in the previous chapter.
<p><strong>Solution:</strong>
  First correct the typo in the problem.
  The first sentence should end at the comma.
  The part from the comma to the period should be part of some other
  problem that tanenbaum was thinking about.
  The business about not being a multiple of block size has nothing to
  do with contiguous allocation so doesn't belong in this problem.
<p>Since the wasted storage is between the allocation units (files),
  not inside them, this is external fragmentation.
  It is precisely analogous to the external fragmentation of main
  memory that occurs with a swapping system of a system using pure
  segmentation.<hr/>

<p><strong>Homework:</strong> Consider an inode-based system with the
  same parameters as just above, D=12, K=250, etc.</p>
<ol>
  <li>What is the largest file that can be stored
    (assume the attributes require 64B)?</li>
  <li>How much space is used to store this largest possible file?</li>
  <li>What percentage of the space used actually holds file data?</li>
  <li>Repeat all the above, now assuming the file system supports a
    triple indirect block.</li>
</ol>
<p><strong>Solution:</strong></p>
<ol>
  <li>We calculate the number of blocks and multiply by the block size.
    <ul>
      <li>The inode points to 12 direct (i.e., data) blocks.</li>
      <li>The inode points to a single indirect block that points to 250
        data blocks.</li>
      <li>The inode points to a double indirect block that points to 250
        single indirect blocks each of which points to 250 data blocks.</li>
      <li>This gives 12 + 250 + 250<sup>2</sup> = 62,762 data blocks.</li>
      <li>This is 62,762,000 bytes.</li>
    </ul>
  </li>
  <li>In addition to the data blocks just calculated we have
    1 inode, 1 double indirect block, (1+250) single indirect
    blocks.
    The 252 blocks require 252,000 bytes.
    The inode has 12+1+1=14 pointers, which require 56B, and has 64B
    of attributes.
    So the total extra storage is 252,120B.</li>
  <li>62,762,000 / (62,762,000 + 252,120) = 99.6%</li>
  <li>The triple indirect block adds both more file data and more
    overhead.
    <ul>
      <li>It adds another 250<sup>3</sup> data blocks or
        15,625,000,000B of file data.</li>
      <li>The extra overhead is 1 triple indirect, 250 double
        indirects, and 250<sup>2</sup> single indirects which totals
        62,751,000B.
        In addition the inode contains a pointer to the triple
        indirect, which adds 4B to the overhead.</li>
      <li>(62,762,000+15,625,000,000) /
        (62,762,000+15,625,000,000+252,120+62,751,000+4)
        = 99.6%</li>
    </ul>
  </li>
</ol>
<hr/>

<p><strong>Problem:</strong> 4.30.
  It has been suggest that the first part of each Unix file be kept in
  the same disk block as its i-node.
  What good would this do?</p>
<p><strong>Solution:</strong>
  Many unix files are short.
  If the entire file fit in the same block
  as the i-node, only one disk access would be needed to read the file,
  instead of two, as is presently the case.
  Even for longer files thee
  would be a gain, since one fewer disk access would be needed to read
  the beginning of the file.</p>

<h2>4.4 File System Management and Optimization</h2>

<p><strong>Problem:</strong> 4.32.
  The performance of a file system depends upon the cache hit rate
  (fraction of blocks found in the cache).
  If it take 1 msec to satisfy a request from the cache, but 40 msec to
  satisfy a request if a disk read is needed, give a formula for the
  mean time required to satisfy a request if the hit rate is h.
  Plot this function for values of h ranging from mo to 1.</p>
<p><strong>Solution:</strong>
  The time needed is</p>
<pre>
  h + 40(1-h).
</pre>
<p>The plot is just a straight line.</p>

</body>
</html>
